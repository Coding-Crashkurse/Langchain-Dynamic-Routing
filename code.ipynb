{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg2://myuser:mypassword@localhost:5433/mydatabase\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "store = PGVector(\n",
    "    collection_name=\"mydatabase\",\n",
    "    connection_string=DATABASE_URL,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "loader = TextLoader(\"./text.txt\")\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=20)\n",
    "chunks =  splitter.split_documents(docs)\n",
    "store.add_documents(chunks)\n",
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke({\"question\": \"Who is the owner of the restaurant?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg2://myuser:mypassword@localhost:5433/mydatabase\"\n",
    "\n",
    "db = SQLDatabase.from_uri(DATABASE_URL)\n",
    "\n",
    "def get_schema(_):\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT name, price\\nFROM products\\nWHERE category = 'Dessert'\\nORDER BY price DESC\\nLIMIT 1;\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | model.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_response.invoke({\"question\": \"Whats the most expensive desert you offer?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most expensive dessert we offer is the \"Tiramisu della Nonna\" priced at $8.50.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: run_query(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sql_chain.invoke({\"question\": \"Whats the most expensive desert you offer?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "classification_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are good at classifying a question.\n",
    "    Given the user question below, classify it as either being about `Database`, `Chat` or 'Offtopic'.\n",
    "\n",
    "    <If the question is about products of the restaurant OR ordering food classify the question as 'Database'>\n",
    "    <If the question is about restaurant related topics like opening hours and similar topics, classify it as 'Chat'>\n",
    "    <If the question is about whether, football or anything not related to the restaurant or\n",
    "    products, classify the question as 'offtopic'>\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    Classification:\"\"\"\n",
    ")\n",
    "\n",
    "classification_chain = (\n",
    "    classification_template\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Offtopic'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_chain.invoke({\"question\": \"How is the wheather?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def route(info):\n",
    "#     print(f\"INFO: {info}\")\n",
    "#     if \"database\" in info[\"topic\"].lower():\n",
    "#         return \"This has to be handled in the database\"\n",
    "#     elif \"chat\" in info[\"topic\"].lower():\n",
    "#         return \"This has to be handled in Chat\"\n",
    "#     else:\n",
    "#         return \"I am sorry, I am not allowed to answer questions about this topic.\"\n",
    "\n",
    "def route(info):\n",
    "    if \"database\" in info[\"topic\"].lower():\n",
    "        return sql_chain\n",
    "    elif \"chat\" in info[\"topic\"].lower():\n",
    "        return rag_chain\n",
    "    else:\n",
    "        return \"I am sorry, I am not allowed to answer about this topic.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = {\"topic\": classification_chain, \"question\": lambda x: x[\"question\"]} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: {'topic': 'Database', 'question': 'Whats the most expensive desert you offer?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This has to be handled in the database'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"Whats the most expensive desert you offer?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: {'topic': 'Offtopic', 'question': 'How will the wheater be tomorrow?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am sorry, I am not allowed to answer questions about this topic.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"How will the wheater be tomorrow?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: {'topic': 'Chat', 'question': 'Who is the owner of the restaurant?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This has to be handled in Chat'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"Who is the owner of the restaurant?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
